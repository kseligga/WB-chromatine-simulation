{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd39aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "np.log1p(math.e - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda4fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic = np.load(\"./hic_050.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b5459",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d816af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f8263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd52cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cc2f73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(hic, vmax=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4221d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(np.arctan(hic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfV = pd.read_csv(\"./data/WB_mesh/d10_V.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc20668",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751956f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfV.id.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd362a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE = pd.read_csv(\"./data/WB_mesh/d10_E.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeca1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae760875",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deb2405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfE.id1.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c0c703",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfE.euc_dist.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3f048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing graph G\n",
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "# getting vertices\n",
    "dfV = pd.read_csv(\"./data/WB_mesh/d10_V.csv\")\n",
    "\n",
    "# adding vertices with coordinates\n",
    "for n, x, y, z in zip(dfV.id, dfV.x, dfV.y, dfV.z):\n",
    "    G.add_node(n, x = x, y = y, z = z)\n",
    "\n",
    "# getting edges\n",
    "dfE = pd.read_csv(\"./data/WB_mesh/d10_E.csv\")\n",
    "    \n",
    "# adding edges with distance and weight\n",
    "for n1, n2, d, w in zip(dfE.id1, dfE.id2, dfE.dist, dfE.weight):\n",
    "    G.add_edge(n1, n2, dist = d, weight = w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37197059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def proponuj_g(structure, G):\n",
    "    \"\"\"\n",
    "    structure = [(x0,y0,z0), ...]\n",
    "    structure = [id0, id1, ...]\n",
    "    G - graf csv, (networkx)\n",
    "    \"\"\"\n",
    "    \n",
    "    id0 = None\n",
    "    \n",
    "    # empty structure\n",
    "    if structure == None or structure == []:\n",
    "        structure = []\n",
    "        # choosing start point index (randomly?)\n",
    "        id0 = random.randint(0, len(G.nodes) - 1)\n",
    "        structure.append(id0)\n",
    "        return structure\n",
    "    \n",
    "    # usuwanie dublujących się krawedzi i testy (może wystarczy)\n",
    "    # dodatkowo rozbudowywanie struktury (ścieżki) w środku, po wspólnych sąsiadach\n",
    "    ## PREZENTACJA\n",
    "    \n",
    "    def add_to_end():\n",
    "        # getting an index of one end of the structure\n",
    "        i = random.choice([0, len(structure) - 1])\n",
    "        end = True\n",
    "        if i == 0:\n",
    "            end = False\n",
    "        id0 = structure[i]\n",
    "        # get indexes of connected vertices\n",
    "        neighbours = list(G[id0].keys())\n",
    "        # finding new edges\n",
    "        neighbours = list(set(neighbours).difference(set(structure)))\n",
    "        if (neighbours == []):\n",
    "            # we allow to rollback, when we are stuck\n",
    "            # neighbours = list(G[id0].keys())\n",
    "            # print(\"No new node has been added.\")\n",
    "            # or we remove stop point\n",
    "            #structure.remove(id0)\n",
    "            structure.pop(i)\n",
    "            # and try somewhere else\n",
    "            return add_in_the_middle()\n",
    "        # taking weights of edges\n",
    "        weights = []\n",
    "        for n in neighbours:\n",
    "            weights.append(G[id0][n]['weight'])\n",
    "            # it may be flattened\n",
    "            # weights.append(np.log1p(G[id0][n]['weight']))\n",
    "        # choosing the next node index\n",
    "        id1 = int(random.choices(neighbours, weights=weights, k=1)[0])\n",
    "        if end:\n",
    "            structure.append(id1)\n",
    "        else:\n",
    "            structure.insert(0, id1)\n",
    "        \n",
    "    def add_in_the_middle():\n",
    "        # finding randomly 2 vertices and inserting additional vertice between them\n",
    "        i = random.randint(0, len(structure) - 2)\n",
    "        id0 = structure[i]\n",
    "        id1 = structure[i+1]\n",
    "        # looking for common neighbours\n",
    "        neighbours0 = list(G[id0].keys())\n",
    "        neighbours1 = list(G[id1].keys())\n",
    "        neighbours0 = set(neighbours0).difference(set(structure))\n",
    "        neighbours1 = set(neighbours1).difference(set(structure))\n",
    "        neighbours = list(neighbours0.intersection(neighbours1))\n",
    "        if (neighbours == []):\n",
    "            # we do not add anything\n",
    "            #print(\"No node has been added.\")\n",
    "            return\n",
    "        # taking weights of edges\n",
    "        weights = []\n",
    "        for n in neighbours:\n",
    "            weights.append(G[id0][n]['weight'] * G[id1][n]['weight'])\n",
    "            # it may be flattened\n",
    "            # weights.append(np.log1p(G[id0][n]['weight']) * np.log1p(G[id1][n]['weight']))\n",
    "        # choosing the next node index\n",
    "        id12 = int(random.choices(neighbours, weights=weights, k=1)[0])\n",
    "        structure.insert(i, id12)\n",
    "        \n",
    "    MIN_MIDDLE_ADD = 10\n",
    "    if len(structure)  < MIN_MIDDLE_ADD:\n",
    "        add_to_end()\n",
    "        return structure\n",
    "    \n",
    "    if random.randint(0, 1) == 0:\n",
    "        add_to_end()\n",
    "    else:\n",
    "        add_in_the_middle()\n",
    "    \n",
    "    return structure\n",
    "   \n",
    "\n",
    "def podobienstwo_f(struktura, mapa_hic):\n",
    "    \"\"\"\n",
    "    oblicza stopień podobieństwa pomiędzy mapą dystansów a mapa hic\n",
    "    pearson, \n",
    "    \"\"\"\n",
    "    \n",
    "    return podobienstwo\n",
    "    \n",
    "\n",
    "def get_structure_coordinates(struktura, G):\n",
    "    def _add(id0):\n",
    "        node = G.nodes[id0]\n",
    "        x = node['x']\n",
    "        y = node['y']\n",
    "        z = node['z']\n",
    "        coordinates.append([x, y, z])\n",
    "    \n",
    "    coordinates = []\n",
    "    for id0 in struktura:\n",
    "        _add(id0)\n",
    "        \n",
    "    return coordinates\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b109e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structure(iterations):\n",
    "    structure = []\n",
    "    for i in range(iterations):\n",
    "        structure = proponuj_g(structure, G)\n",
    "    #print(\"Structure contains \" + str(len(structure)) + \" vertices.\" )\n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3df8144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719.01\n",
      "1298\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#initializing structure\n",
    "v_n = []\n",
    "for i in range(100):\n",
    "    s = create_structure(5000)\n",
    "    v_n.append(len(s))\n",
    "print(np.mean(v_n)) # 420\n",
    "print(np.max(v_n)) # 700\n",
    "print(np.min(v_n)) # 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f62ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tworzenie struktury\n",
    "struktura = []\n",
    "for i in range(1000):\n",
    "    struktura = proponuj_g(struktura, G)\n",
    "#print(struktura)\n",
    "print(len(struktura))\n",
    "print(len(np.unique(struktura)))\n",
    "print(len(np.unique(struktura)) / len(struktura))\n",
    "#print(get_structure_coordinates(struktura, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c52855",
   "metadata": {},
   "outputs": [],
   "source": [
    "struktura = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "struktura = proponuj_g(struktura, G)\n",
    "print((struktura))\n",
    "if (len(np.unique(struktura)) != len(struktura)):\n",
    "    print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607f182",
   "metadata": {},
   "source": [
    "Tera Czarek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7004c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.spatial import distance_matrix\n",
    "import math as m\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318934b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hic = np.load(\"hic_020.npy\")\n",
    "\n",
    "\n",
    "def distance_map(structure):\n",
    "    # returns distance map of given structure\n",
    "    map_ = distance_matrix(structure, structure)\n",
    "    return map_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec17997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_midpoint(point1, point2):\n",
    "    return [(point1[0] + point2[0])/2, (point1[1] + point2[1])/2, (point1[2] + point2[2])/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ed734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_points_to_structure(structure, dim):\n",
    "    '''\n",
    "    adds points to the structure so it hase same dimension as dim (hic matrix)\n",
    "    '''\n",
    "    n = len(structure)\n",
    "    new_structure = []\n",
    "    nr_points = dim - n\n",
    "    if nr_points > 0:\n",
    "        for i in range(nr_points):\n",
    "            nr_used = len(new_structure) - i\n",
    "            new_structure.append(structure[nr_used : nr_used + m.floor((i+1)*n/nr_points)])\n",
    "            new_structure.append(calc_midpoint(structure[nr_used + m.floor((i+1)*n/nr_points - 1)], structure[nr_used + m.floor((i+1)*n/nr_points)]))\n",
    "        new_structure.append(structure[len(new_structure) - nr_points + 1 :])\n",
    "        # trochę sus, bo dodajemy na końcu, midpoints między wybranymi punktami\n",
    "        return new_structure\n",
    "    elif nr_points == 0:\n",
    "        return structure\n",
    "    else:\n",
    "        return structure[:dim] #todo lepiej\n",
    "        # nie ucinać ostatnich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d269766",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def reverse_matr(matr):\n",
    "    m = np.asarray(matr)\n",
    "    return m/(m*m)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1edebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def calc_corr(matr1, matr2):\n",
    "    corr, _ = pearsonr(matr1.flatten(), matr2.flatten())\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_similarity(structure, hic):\n",
    "    dim = len(hic)\n",
    "    structure = add_points_to_structure(structure, dim)\n",
    "    dist_map = distance_map(structure)\n",
    "    reversed_hic = reverse_matr(hic)\n",
    "    return calc_corr(reversed_hic, dist_map)\n",
    "    \n",
    "structure = [[1, i+1, i*2] for i in range(20)]\n",
    "f_similarity(structure, hic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae367c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba850fd5",
   "metadata": {},
   "source": [
    "# simulated annealing\n",
    "zmniejszanie temperatury, w celu znalezienia max globalnego\n",
    "zależy od możliwości ruchu w g\n",
    "na początek infalcja - rozszerzanie struktury\n",
    "\n",
    "Zaczynamy od temperatury T0 i jakiejś struktury.\n",
    "Nowa struktura z g na podstawie f i aktualnej temperatury.\n",
    "Zazwyczaj min(exp(-fx-fy/T), 1), liczymy różnice w podobieństwie dla dwóch struktur x i y\n",
    "wybieramy kolejne punkty na podstawie tego i rozbudowujemy jedną ścieżkę\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76e157",
   "metadata": {},
   "source": [
    "# MCMC\n",
    "\n",
    "próbkowanie Gibbsa - najprostsze, ale tego się nie używa w tym projekcie\n",
    "losowanie xs w celu zamodelowania wielowymiarowej gęstości\n",
    "\n",
    "algorytm Metropolisa-Hastingsa - to mamy zrobić (zalecenie prowadzącego)\n",
    "losuje ścieżki, w całości\n",
    "dostajemy zbiór wielu ścieżek\n",
    "wybieramy najlepsze, albo coś z nich łączymy\n",
    "\n",
    "losujemy nową strukturę, którą akceptujemy lub nie\n",
    "\n",
    "wzorki są na slajdach (najprościej min(fy/fx, 1) dla symetrycznych gęstości - możemy to założyć)\n",
    "albo liczymy prawdopodobieństwa wylosowania kolejnych struktur, można zwracać p-stwa w funkcji g utworzenia danej ścieżki, wystarczy wtedy wymnażać sobie wagi, może jakoś przeskalować, ale można też pominąć i się nie męczyć (prowadzący nie będzie się czepiał)\n",
    "\n",
    "f liczymy z funkcji podobieństwa\n",
    "\n",
    "w symulacjach, jak mamy wykresik, odcinamy początek, bo jest zawsze skorelowany\n",
    "można odpalić mcmc kilka razy\n",
    "\n",
    "\n",
    "po sym. wyrza... otrzymujemy jedną strukturę\n",
    "po mcmc otrzymujemy całą próbkę, wiele struktur\n",
    "z nich wybieramy pewnie najlepszą\n",
    "\n",
    "ale można też zaszaleć\n",
    "\n",
    "w wynikach mają być wykresy podobieństwa f względem ilości iteracji\n",
    "\n",
    "ale można szaleć\n",
    "\n",
    "krótka prezentacja 5 - 10 slajdów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9efb48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulated annealing\n",
    "\n",
    "def simulated_annealing(iterations, hic):\n",
    "    import copy\n",
    "    import math\n",
    "    import random\n",
    "    \n",
    "    # initializing structure and start temperature\n",
    "    structure = proponuj_g(None, G)\n",
    "    T_0 = 1\n",
    "    probabilities = []\n",
    "    \n",
    "    for i in range(1, iterations):\n",
    "        # decreasing T\n",
    "        T = T_0 * (1 - i/iterations)\n",
    "        # proposing a new point to structure\n",
    "        new_structure = copy.deepcopy(structure)\n",
    "        new_structure = proponuj_g(new_structure, G)\n",
    "        # counting probability of selecting new_structure\n",
    "        p = min(math.exp((-1) * (f_similarity(structure, hic) - f_similarity(new_structure, hic)) / T), 1)\n",
    "        # saving probability for creating charts\n",
    "        probabilities.append(p)\n",
    "        # choosing structure\n",
    "        if random.random() <= p:\n",
    "            structure = new_structure\n",
    "    return structure, probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd7055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd0aa6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.718281828459045"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.exp(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa9a39b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08254083729662398"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.random()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
